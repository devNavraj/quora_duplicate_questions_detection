{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"deep_nn_test1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"code","metadata":{"id":"Qcn-2T-FgJ7R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637548934287,"user_tz":-345,"elapsed":28867,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"5988ee98-ac13-4904-b49b-d3657ad879cd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"Qcn-2T-FgJ7R","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"bbpUKH7AgUty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637548939733,"user_tz":-345,"elapsed":535,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"30f9b940-e3d9-4c61-8f72-d7e654523be1"},"source":["cd drive/MyDrive/quora_duplicate_questions_detection/"],"id":"bbpUKH7AgUty","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1NfDfMFFEa6jbcf5EQ_tVWbvhytT96tlt/quora_duplicate_questions_detection\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acLkcU34hf6Y","executionInfo":{"status":"ok","timestamp":1637548954489,"user_tz":-345,"elapsed":508,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"c4d6e1b3-14ee-4d1e-bd1f-744845981cad"},"source":["!ls"],"id":"acLkcU34hf6Y","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" classifier.py\t\t  feature_engineering.ipynb   __pycache__\n","'Copy of deep_nn.ipynb'   graphs\t\t      tfidf_model.ipynb\n"," data\t\t\t  __init__.py\t\t      Untitled.ipynb\n"," deep_nn-Copy1.ipynb\t  nlp_features.ipynb\t      utils.py\n"," deep_nn.ipynb\t\t  non_nlp_features.ipynb\n"]}]},{"cell_type":"code","metadata":{"id":"57372a3f-d81f-4a5c-b485-2f0b3d16b8e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637549252453,"user_tz":-345,"elapsed":551,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"0bfa417d-4e59-4f7a-f685-5138362eef34"},"source":["import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import StratifiedKFold\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense, Input, LSTM, Embedding, Dropout\n","from keras.layers.core import Lambda\n","from keras.layers.merge import concatenate, add, multiply\n","from keras.models import Model\n","from keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.layers.noise import GaussianNoise\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.corpus import stopwords"],"id":"57372a3f-d81f-4a5c-b485-2f0b3d16b8e4","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"4d58ce9a-b08c-475f-a2de-9e816121cad1"},"source":["np.random.seed(0)\n","WNL = WordNetLemmatizer()\n","STOP_WORDS = set(stopwords.words('english'))\n","MAX_SEQUENCE_LENGTH = 30\n","MIN_WORD_OCCURRENCE = 100\n","REPLACE_WORD = \"rare\"\n","EMBEDDING_DIM = 300\n","NUM_FOLDS = 10\n","BATCH_SIZE = 256\n","EMBEDDING_FILE = \"data/glove.840B.300d.txt\""],"id":"4d58ce9a-b08c-475f-a2de-9e816121cad1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ad68582-dafd-4a3a-9f82-e714683c2f97"},"source":["def cutter(word):\n","    if len(word) < 4:\n","        return word\n","    return WNL.lemmatize(WNL.lemmatize(word, \"n\"), \"v\")"],"id":"5ad68582-dafd-4a3a-9f82-e714683c2f97","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0f3e9f0-7c9f-40b8-8595-0a562ab94d5a"},"source":["def preprocess(string):\n","    string = string.lower().replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\") \\\n","        .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\") \\\n","        .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\") \\\n","        .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\") \\\n","        .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\") \\\n","        .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \") \\\n","        .replace(\"€\", \" euro \").replace(\"'ll\", \" will\").replace(\"=\", \" equal \").replace(\"+\", \" plus \")\n","    string = re.sub('[“”\\(\\'…\\)\\!\\^\\\"\\.;:,\\-\\?？\\{\\}\\[\\]\\\\/\\*@]', ' ', string)\n","    string = re.sub(r\"([0-9]+)000000\", r\"\\1m\", string)\n","    string = re.sub(r\"([0-9]+)000\", r\"\\1k\", string)\n","    string = ' '.join([cutter(w) for w in string.split()])\n","    return string"],"id":"f0f3e9f0-7c9f-40b8-8595-0a562ab94d5a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"501b4ba4-23c1-4ea7-9d93-a5d4a844e14a"},"source":["def get_embedding():\n","    embeddings_index = {}\n","    f = open(EMBEDDING_FILE, encoding=\"utf8\")\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        if len(values) == EMBEDDING_DIM + 1 and word in top_words:\n","            coefs = np.asarray(values[1:], dtype=\"float32\")\n","            embeddings_index[word] = coefs\n","    f.close()\n","    return embeddings_index"],"id":"501b4ba4-23c1-4ea7-9d93-a5d4a844e14a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2954e72-5b88-4a41-bffd-1df6f0a45adb"},"source":["def is_numeric(s):\n","    return any(i.isdigit() for i in s)"],"id":"c2954e72-5b88-4a41-bffd-1df6f0a45adb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6b4169fe-879f-40cd-9cb1-bec00dd8d9c3"},"source":["def prepare(q):\n","    new_q = []\n","    surplus_q = []\n","    numbers_q = []\n","    new_rare = True\n","    for w in q.split()[::-1]:\n","        if w in top_words:\n","            new_q = [w] + new_q\n","            new_rare = True\n","        elif w not in STOP_WORDS:\n","            if new_rare:\n","                new_q = [\"rare\"] + new_q\n","                new_rare = False\n","            if is_numeric(w):\n","                numbers_q = [w] + numbers_q\n","            else:\n","                surplus_q = [w] + surplus_q\n","        else:\n","            new_rare = True\n","        if len(new_q) == MAX_SEQUENCE_LENGTH:\n","            break\n","    new_q = \" \".join(new_q)\n","    return new_q, set(surplus_q), set(numbers_q)"],"id":"6b4169fe-879f-40cd-9cb1-bec00dd8d9c3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bd17c5f6-5d8b-471b-b1f0-627527b4c8aa"},"source":["def extract_features(df):\n","    q1s = np.array([\"\"] * len(df), dtype=object)\n","    q2s = np.array([\"\"] * len(df), dtype=object)\n","    features = np.zeros((len(df), 4))\n","\n","    for i, (q1, q2) in enumerate(list(zip(df[\"question1\"], df[\"question2\"]))):\n","        q1s[i], surplus1, numbers1 = prepare(q1)\n","        q2s[i], surplus2, numbers2 = prepare(q2)\n","        features[i, 0] = len(surplus1.intersection(surplus2))\n","        features[i, 1] = len(surplus1.union(surplus2))\n","        features[i, 2] = len(numbers1.intersection(numbers2))\n","        features[i, 3] = len(numbers1.union(numbers2))\n","\n","    return q1s, q2s, features"],"id":"bd17c5f6-5d8b-471b-b1f0-627527b4c8aa","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60ea81a7-37dd-4df6-97c2-7c7224b5be40"},"source":["train = pd.read_csv(\"data/train.csv\")\n","test = pd.read_csv(\"data/test.csv\")"],"id":"60ea81a7-37dd-4df6-97c2-7c7224b5be40","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7zLE1DcDEGy"},"source":["train[\"question1\"] = train[\"question1\"].fillna(\"\").apply(preprocess)\n","train[\"question2\"] = train[\"question2\"].fillna(\"\").apply(preprocess)"],"id":"c7zLE1DcDEGy","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQCaJfWkDH0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637549341837,"user_tz":-345,"elapsed":7047,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"3c3f7bc4-f73e-4d91-a3a0-62130c419334"},"source":["print(\"Creating the vocabulary of words occurred more than\", MIN_WORD_OCCURRENCE)\n","all_questions = pd.Series(train[\"question1\"].tolist() + train[\"question2\"].tolist()).unique()\n","vectorizer = CountVectorizer(lowercase=False, token_pattern=\"\\S+\", min_df=MIN_WORD_OCCURRENCE)\n","vectorizer.fit(all_questions)\n","top_words = set(vectorizer.vocabulary_.keys())\n","top_words.add(REPLACE_WORD)"],"id":"PQCaJfWkDH0U","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating the vocabulary of words occurred more than 100\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD2ZmcmhDXKG","executionInfo":{"status":"ok","timestamp":1637549472785,"user_tz":-345,"elapsed":108365,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"f1a81860-e761-4ce3-be16-949cbf9964da"},"source":["embeddings_index = get_embedding()\n","print(\"Words are not found in the embedding:\", top_words - embeddings_index.keys())\n","top_words = embeddings_index.keys()"],"id":"qD2ZmcmhDXKG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Words are not found in the embedding: {'demonetisation', 'brexit', 'paytm', 'iisc', '\\\\sqrt', '\\\\frac', 'c#', 'quorans', 'redmi', 'oneplus', 'kvpy'}\n"]}]},{"cell_type":"code","metadata":{"id":"2b767ccc-7bc3-49a8-b869-1ce22462b534","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637549527021,"user_tz":-345,"elapsed":7651,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"24a7ffd8-137e-4608-fd5e-437968f27f05"},"source":["print(\"Train questions are being prepared for LSTM...\")\n","q1s_train, q2s_train, train_q_features = extract_features(train)"],"id":"2b767ccc-7bc3-49a8-b869-1ce22462b534","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train questions are being prepared for LSTM...\n"]}]},{"cell_type":"code","metadata":{"id":"3gDEpe1RD4xB"},"source":["tokenizer = Tokenizer(filters=\"\")\n","tokenizer.fit_on_texts(np.append(q1s_train, q2s_train))\n","word_index = tokenizer.word_index"],"id":"3gDEpe1RD4xB","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9wj-8siEV7a"},"source":["data_1 = pad_sequences(tokenizer.texts_to_sequences(q1s_train), maxlen=MAX_SEQUENCE_LENGTH)\n","data_2 = pad_sequences(tokenizer.texts_to_sequences(q2s_train), maxlen=MAX_SEQUENCE_LENGTH)\n","labels = np.array(train[\"is_duplicate\"])"],"id":"y9wj-8siEV7a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lz9joHcdDeYn"},"source":["nb_words = len(word_index) + 1\n","embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))"],"id":"Lz9joHcdDeYn","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92efe483-b3cd-4c68-b313-e04dd01024cb"},"source":["for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector"],"id":"92efe483-b3cd-4c68-b313-e04dd01024cb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cc6bef1-02f9-4d01-b811-a9610582a2a2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637549573411,"user_tz":-345,"elapsed":3765,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"38f6211a-1167-464f-83dd-98a5bedc8ebb"},"source":["print(\"Train features are being merged with NLP and Non-NLP features...\")\n","train_nlp_features = pd.read_csv(\"data/nlp_features_train.csv\")\n","train_non_nlp_features = pd.read_csv(\"data/non_nlp_features_train.csv\")\n","features_train = np.hstack((train_q_features, train_nlp_features, train_non_nlp_features))"],"id":"9cc6bef1-02f9-4d01-b811-a9610582a2a2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train features are being merged with NLP and Non-NLP features...\n"]}]},{"cell_type":"code","metadata":{"id":"7f366bee-de60-468d-89d1-822b7726705b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637550046475,"user_tz":-345,"elapsed":469165,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"a75663ed-a74f-4b14-dcd3-cf51625f5b76"},"source":["print(\"Same steps are being applied for test...\")\n","test[\"question1\"] = test[\"question1\"].fillna(\"\").apply(preprocess)\n","test[\"question2\"] = test[\"question2\"].fillna(\"\").apply(preprocess)\n","\n","q1s_test, q2s_test, test_q_features = extract_features(test)\n","\n","test_data_1 = pad_sequences(tokenizer.texts_to_sequences(q1s_test), maxlen=MAX_SEQUENCE_LENGTH)\n","test_data_2 = pad_sequences(tokenizer.texts_to_sequences(q2s_test), maxlen=MAX_SEQUENCE_LENGTH)\n","\n","test_nlp_features = pd.read_csv(\"data/nlp_features_test.csv\")\n","test_non_nlp_features = pd.read_csv(\"data/non_nlp_features_test.csv\")\n","features_test = np.hstack((test_q_features, test_nlp_features, test_non_nlp_features))"],"id":"7f366bee-de60-468d-89d1-822b7726705b","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Same steps are being applied for test...\n"]}]},{"cell_type":"code","metadata":{"id":"2df7faa3-0cd2-4784-903d-3629f16e22c1"},"source":["stratified_kf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True)\n","model_count = 0"],"id":"2df7faa3-0cd2-4784-903d-3629f16e22c1","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d4803b8c-9247-4906-a168-b8ac3bbe6ba1","colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"status":"error","timestamp":1637550146805,"user_tz":-345,"elapsed":55674,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"5cb00059-7248-4cfd-9bac-c2a11c2144aa"},"source":["for idx_train, idx_val in stratified_kf.split(train[\"is_duplicate\"], train[\"is_duplicate\"]):\n","    print(\"MODEL:\", model_count)\n","    data_1_train = data_1[idx_train]\n","    data_2_train = data_2[idx_train]\n","    labels_train = labels[idx_train]\n","    f_train = features_train[idx_train]\n","\n","    data_1_val = data_1[idx_val]\n","    data_2_val = data_2[idx_val]\n","    labels_val = labels[idx_val]\n","    f_val = features_train[idx_val]\n","\n","    embedding_layer = Embedding(nb_words,\n","                                EMBEDDING_DIM,\n","                                weights=[embedding_matrix],\n","                                input_length=MAX_SEQUENCE_LENGTH,\n","                                trainable=False)\n","\n","    lstm_layer = LSTM(75, recurrent_dropout=0.2)\n","\n","    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n","    embedded_sequences_1 = embedding_layer(sequence_1_input)\n","    x1 = lstm_layer(embedded_sequences_1)\n","\n","    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n","    embedded_sequences_2 = embedding_layer(sequence_2_input)\n","    y1 = lstm_layer(embedded_sequences_2)\n","\n","    features_input = Input(shape=(f_train.shape[1],), dtype=\"float32\")\n","    features_dense = BatchNormalization()(features_input)\n","    features_dense = Dense(200, activation=\"relu\")(features_dense)\n","    features_dense = Dropout(0.2)(features_dense)\n","\n","    addition = add([x1, y1])\n","    minus_y1 = Lambda(lambda x: -x)(y1)\n","    merged = add([x1, minus_y1])\n","    merged = multiply([merged, merged])\n","    merged = concatenate([merged, addition])\n","    merged = Dropout(0.4)(merged)\n","\n","    merged = concatenate([merged, features_dense])\n","    merged = BatchNormalization()(merged)\n","    merged = GaussianNoise(0.1)(merged)\n","\n","    merged = Dense(150, activation=\"relu\")(merged)\n","    merged = Dropout(0.2)(merged)\n","    merged = BatchNormalization()(merged)\n","\n","    out = Dense(1, activation=\"sigmoid\")(merged)\n","\n","    model = Model(inputs=[sequence_1_input, sequence_2_input, features_input], outputs=out)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n","    best_model_path = \"best_model\" + str(model_count) + \".h5\"\n","    model_checkpoint = ModelCheckpoint(best_model_path, save_best_only=True, save_weights_only=True)\n","\n","    model_history = model.fit([data_1_train, data_2_train, f_train], labels_train, \n","                     batch_size=BATCH_SIZE, epochs=25, shuffle=True,\n","                     validation_data=([data_1_val, data_2_val, f_val], labels_val),\n","                     callbacks=[early_stopping, model_checkpoint], verbose=1)\n","\n","    model.load_weights(best_model_path)\n","    print(model_count, \"validation loss:\", min(model_history.history[\"val_loss\"]))\n","    print(model_count, \"validation loss:\", max(model_history.history[\"val_accuracy\"]))\n","    preds = model.predict([test_data_1, test_data_2, features_test], batch_size=BATCH_SIZE, verbose=1)\n","\n","    submission = pd.DataFrame({\"test_id\": test[\"test_id\"], \"is_duplicate\": preds.ravel()})\n","    submission.to_csv(\"predictions/preds\" + str(model_count) + \".csv\", index=False)\n","\n","    model_count += 1"],"id":"d4803b8c-9247-4906-a168-b8ac3bbe6ba1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MODEL: 0\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Epoch 1/25\n"," 144/2843 [>.............................] - ETA: 13:30 - loss: 0.3687 - accuracy: 0.8275"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-d2c452d069e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                      callbacks=[early_stopping, model_checkpoint], verbose=1)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4eb48e02-4430-4877-b5cf-a07e9a3b2120","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637558812566,"user_tz":-345,"elapsed":7301797,"user":{"displayName":"Nawaraj Rai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiP8nNWGQE6C0QTqZd3RsxqIB9YgVLW9Jgs0CEl_Q=s64","userId":"09316666119230139328"}},"outputId":"f80486b7-7e64-48b8-b6a3-56e3e64e73ae"},"source":["'''With recurrent_dropout=0.2 get \"not use cuDNN kernel\" warning and time increases\n","to ~ 1 min per epoch & get following results for first fold:\n","validation loss: 0.20543508231639862\n","Wall time: 15min 58s - for complete run of 15 epochs & validation\n","\n","with no recurrent_dropout cuDNN kernel is used ~ 9 seconds per epoch\n","validation loss: 0.20922143757343292\n","Wall time: 3min 10s'''\n","for idx_train, idx_val in stratified_kf.split(train[\"is_duplicate\"], train[\"is_duplicate\"]):\n","    print(\"MODEL:\", model_count)\n","    data_1_train = data_1[idx_train]\n","    data_2_train = data_2[idx_train]\n","    labels_train = labels[idx_train]\n","    f_train = features_train[idx_train]\n","\n","    data_1_val = data_1[idx_val]\n","    data_2_val = data_2[idx_val]\n","    labels_val = labels[idx_val]\n","    f_val = features_train[idx_val]\n","\n","    embedding_layer = Embedding(nb_words,\n","                                EMBEDDING_DIM,\n","                                weights=[embedding_matrix],\n","                                input_length=MAX_SEQUENCE_LENGTH,\n","                                trainable=False)\n","\n","    # lstm_layer = LSTM(75, recurrent_dropout=0.2)\n","    lstm_layer = LSTM(75)\n","\n","    sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n","    embedded_sequences_1 = embedding_layer(sequence_1_input)\n","    x1 = lstm_layer(embedded_sequences_1)\n","\n","    sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n","    embedded_sequences_2 = embedding_layer(sequence_2_input)\n","    y1 = lstm_layer(embedded_sequences_2)\n","\n","    features_input = Input(shape=(f_train.shape[1],), dtype=\"float32\")\n","    features_dense = BatchNormalization()(features_input)\n","    features_dense = Dense(200, activation=\"relu\")(features_dense)\n","    features_dense = Dropout(0.2)(features_dense)\n","\n","    addition = add([x1, y1])\n","    minus_y1 = Lambda(lambda x: -x)(y1)\n","    merged = add([x1, minus_y1])\n","    merged = multiply([merged, merged])\n","    merged = concatenate([merged, addition])\n","    merged = Dropout(0.4)(merged)\n","\n","    merged = concatenate([merged, features_dense])\n","    merged = BatchNormalization()(merged)\n","    merged = GaussianNoise(0.1)(merged)\n","\n","    merged = Dense(150, activation=\"relu\")(merged)\n","    merged = Dropout(0.2)(merged)\n","    merged = BatchNormalization()(merged)\n","\n","    out = Dense(1, activation=\"sigmoid\")(merged)\n","\n","    model = Model(inputs=[sequence_1_input, sequence_2_input, features_input], outputs=out)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n","    best_model_path = \"models/test1/best_model\" + str(model_count) + \".h5\"\n","    model_checkpoint = ModelCheckpoint(best_model_path, save_best_only=True, save_weights_only=True)\n","\n","    model_history = model.fit([data_1_train, data_2_train, f_train], labels_train, \n","                     batch_size=BATCH_SIZE, epochs=25, shuffle=True,\n","                     validation_data=([data_1_val, data_2_val, f_val], labels_val),\n","                     callbacks=[early_stopping, model_checkpoint], verbose=1)\n","\n","    model.load_weights(best_model_path)\n","    print(model_count, \"validation loss:\", min(model_history.history[\"val_loss\"]))\n","\n","    preds = model.predict([test_data_1, test_data_2, features_test], batch_size=BATCH_SIZE, verbose=1)\n","\n","    submission = pd.DataFrame({\"test_id\": test[\"test_id\"], \"is_duplicate\": preds.ravel()})\n","    submission.to_csv(\"predictions/test1/preds\" + str(model_count) + \".csv\", index=False)\n","\n","    model_count += 1"],"id":"4eb48e02-4430-4877-b5cf-a07e9a3b2120","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MODEL: 0\n","Epoch 1/25\n","1422/1422 [==============================] - 45s 28ms/step - loss: 0.2728 - accuracy: 0.8719 - val_loss: 0.2362 - val_accuracy: 0.8898\n","Epoch 2/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2396 - accuracy: 0.8911 - val_loss: 0.2208 - val_accuracy: 0.9014\n","Epoch 3/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2270 - accuracy: 0.8977 - val_loss: 0.2132 - val_accuracy: 0.9054\n","Epoch 4/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2183 - accuracy: 0.9023 - val_loss: 0.2115 - val_accuracy: 0.9058\n","Epoch 5/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2101 - accuracy: 0.9067 - val_loss: 0.2062 - val_accuracy: 0.9098\n","Epoch 6/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2045 - accuracy: 0.9100 - val_loss: 0.2045 - val_accuracy: 0.9094\n","Epoch 7/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1992 - accuracy: 0.9125 - val_loss: 0.2044 - val_accuracy: 0.9097\n","Epoch 8/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1944 - accuracy: 0.9145 - val_loss: 0.2042 - val_accuracy: 0.9107\n","Epoch 9/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1900 - accuracy: 0.9170 - val_loss: 0.2012 - val_accuracy: 0.9110\n","Epoch 10/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1863 - accuracy: 0.9184 - val_loss: 0.2017 - val_accuracy: 0.9115\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1820 - accuracy: 0.9207 - val_loss: 0.2012 - val_accuracy: 0.9118\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1781 - accuracy: 0.9226 - val_loss: 0.2008 - val_accuracy: 0.9116\n","Epoch 13/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1747 - accuracy: 0.9242 - val_loss: 0.2024 - val_accuracy: 0.9117\n","Epoch 14/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1719 - accuracy: 0.9255 - val_loss: 0.2052 - val_accuracy: 0.9115\n","Epoch 15/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1687 - accuracy: 0.9274 - val_loss: 0.2041 - val_accuracy: 0.9123\n","Epoch 16/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1655 - accuracy: 0.9291 - val_loss: 0.2070 - val_accuracy: 0.9119\n","Epoch 17/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1628 - accuracy: 0.9301 - val_loss: 0.2083 - val_accuracy: 0.9109\n","0 validation loss: 0.20082151889801025\n","9164/9164 [==============================] - 70s 8ms/step\n","MODEL: 1\n","Epoch 1/25\n","1422/1422 [==============================] - 45s 28ms/step - loss: 0.2741 - accuracy: 0.8718 - val_loss: 0.2373 - val_accuracy: 0.8922\n","Epoch 2/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2399 - accuracy: 0.8912 - val_loss: 0.2245 - val_accuracy: 0.8993\n","Epoch 3/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2264 - accuracy: 0.8985 - val_loss: 0.2178 - val_accuracy: 0.9021\n","Epoch 4/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2169 - accuracy: 0.9033 - val_loss: 0.2145 - val_accuracy: 0.9036\n","Epoch 5/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2103 - accuracy: 0.9069 - val_loss: 0.2124 - val_accuracy: 0.9048\n","Epoch 6/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2041 - accuracy: 0.9102 - val_loss: 0.2095 - val_accuracy: 0.9068\n","Epoch 7/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1982 - accuracy: 0.9131 - val_loss: 0.2071 - val_accuracy: 0.9070\n","Epoch 8/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1931 - accuracy: 0.9158 - val_loss: 0.2059 - val_accuracy: 0.9077\n","Epoch 9/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1886 - accuracy: 0.9176 - val_loss: 0.2074 - val_accuracy: 0.9071\n","Epoch 10/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1843 - accuracy: 0.9201 - val_loss: 0.2081 - val_accuracy: 0.9060\n","Epoch 11/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1806 - accuracy: 0.9217 - val_loss: 0.2080 - val_accuracy: 0.9069\n","Epoch 12/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1767 - accuracy: 0.9231 - val_loss: 0.2066 - val_accuracy: 0.9079\n","Epoch 13/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1734 - accuracy: 0.9253 - val_loss: 0.2091 - val_accuracy: 0.9082\n","1 validation loss: 0.20586013793945312\n","9164/9164 [==============================] - 70s 8ms/step\n","MODEL: 2\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 28ms/step - loss: 0.2736 - accuracy: 0.8729 - val_loss: 0.2411 - val_accuracy: 0.8878\n","Epoch 2/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2395 - accuracy: 0.8913 - val_loss: 0.2256 - val_accuracy: 0.8988\n","Epoch 3/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2267 - accuracy: 0.8981 - val_loss: 0.2157 - val_accuracy: 0.9026\n","Epoch 4/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.2177 - accuracy: 0.9027 - val_loss: 0.2191 - val_accuracy: 0.9002\n","Epoch 5/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.2107 - accuracy: 0.9069 - val_loss: 0.2096 - val_accuracy: 0.9061\n","Epoch 6/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2039 - accuracy: 0.9096 - val_loss: 0.2075 - val_accuracy: 0.9070\n","Epoch 7/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1991 - accuracy: 0.9126 - val_loss: 0.2053 - val_accuracy: 0.9087\n","Epoch 8/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1942 - accuracy: 0.9153 - val_loss: 0.2045 - val_accuracy: 0.9088\n","Epoch 9/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1901 - accuracy: 0.9173 - val_loss: 0.2052 - val_accuracy: 0.9085\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1857 - accuracy: 0.9190 - val_loss: 0.2037 - val_accuracy: 0.9086\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1814 - accuracy: 0.9213 - val_loss: 0.2035 - val_accuracy: 0.9104\n","Epoch 12/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1785 - accuracy: 0.9227 - val_loss: 0.2054 - val_accuracy: 0.9087\n","Epoch 13/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1743 - accuracy: 0.9252 - val_loss: 0.2062 - val_accuracy: 0.9098\n","Epoch 14/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1720 - accuracy: 0.9260 - val_loss: 0.2082 - val_accuracy: 0.9073\n","Epoch 15/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1681 - accuracy: 0.9280 - val_loss: 0.2087 - val_accuracy: 0.9097\n","Epoch 16/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1654 - accuracy: 0.9292 - val_loss: 0.2072 - val_accuracy: 0.9097\n","2 validation loss: 0.2034732848405838\n","9164/9164 [==============================] - 70s 8ms/step\n","MODEL: 3\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 28ms/step - loss: 0.2725 - accuracy: 0.8730 - val_loss: 0.2391 - val_accuracy: 0.8890\n","Epoch 2/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2390 - accuracy: 0.8911 - val_loss: 0.2250 - val_accuracy: 0.8970\n","Epoch 3/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2267 - accuracy: 0.8982 - val_loss: 0.2209 - val_accuracy: 0.9009\n","Epoch 4/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.2174 - accuracy: 0.9031 - val_loss: 0.2108 - val_accuracy: 0.9061\n","Epoch 5/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.2104 - accuracy: 0.9067 - val_loss: 0.2099 - val_accuracy: 0.9066\n","Epoch 6/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2039 - accuracy: 0.9102 - val_loss: 0.2102 - val_accuracy: 0.9064\n","Epoch 7/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1982 - accuracy: 0.9128 - val_loss: 0.2103 - val_accuracy: 0.9069\n","Epoch 8/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1934 - accuracy: 0.9155 - val_loss: 0.2066 - val_accuracy: 0.9078\n","Epoch 9/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1887 - accuracy: 0.9177 - val_loss: 0.2044 - val_accuracy: 0.9095\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1839 - accuracy: 0.9195 - val_loss: 0.2073 - val_accuracy: 0.9077\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1811 - accuracy: 0.9210 - val_loss: 0.2032 - val_accuracy: 0.9084\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1766 - accuracy: 0.9234 - val_loss: 0.2068 - val_accuracy: 0.9087\n","Epoch 13/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1729 - accuracy: 0.9257 - val_loss: 0.2078 - val_accuracy: 0.9092\n","Epoch 14/25\n","1422/1422 [==============================] - 38s 27ms/step - loss: 0.1701 - accuracy: 0.9264 - val_loss: 0.2055 - val_accuracy: 0.9099\n","Epoch 15/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1671 - accuracy: 0.9278 - val_loss: 0.2079 - val_accuracy: 0.9085\n","Epoch 16/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1647 - accuracy: 0.9290 - val_loss: 0.2070 - val_accuracy: 0.9083\n","3 validation loss: 0.20318163931369781\n","9164/9164 [==============================] - 72s 8ms/step\n","MODEL: 4\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 28ms/step - loss: 0.2762 - accuracy: 0.8711 - val_loss: 0.2386 - val_accuracy: 0.8920\n","Epoch 2/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.2410 - accuracy: 0.8904 - val_loss: 0.2218 - val_accuracy: 0.8983\n","Epoch 3/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2277 - accuracy: 0.8975 - val_loss: 0.2159 - val_accuracy: 0.9045\n","Epoch 4/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2195 - accuracy: 0.9017 - val_loss: 0.2086 - val_accuracy: 0.9070\n","Epoch 5/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2119 - accuracy: 0.9061 - val_loss: 0.2049 - val_accuracy: 0.9079\n","Epoch 6/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2057 - accuracy: 0.9090 - val_loss: 0.2043 - val_accuracy: 0.9084\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2001 - accuracy: 0.9116 - val_loss: 0.2043 - val_accuracy: 0.9076\n","Epoch 8/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1952 - accuracy: 0.9142 - val_loss: 0.2011 - val_accuracy: 0.9099\n","Epoch 9/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1910 - accuracy: 0.9166 - val_loss: 0.2029 - val_accuracy: 0.9091\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1862 - accuracy: 0.9187 - val_loss: 0.2006 - val_accuracy: 0.9109\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1821 - accuracy: 0.9206 - val_loss: 0.2017 - val_accuracy: 0.9115\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1788 - accuracy: 0.9222 - val_loss: 0.2003 - val_accuracy: 0.9106\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1766 - accuracy: 0.9231 - val_loss: 0.2058 - val_accuracy: 0.9090\n","Epoch 14/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1726 - accuracy: 0.9253 - val_loss: 0.2037 - val_accuracy: 0.9104\n","Epoch 15/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1696 - accuracy: 0.9268 - val_loss: 0.2009 - val_accuracy: 0.9113\n","Epoch 16/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1661 - accuracy: 0.9286 - val_loss: 0.2029 - val_accuracy: 0.9104\n","Epoch 17/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1638 - accuracy: 0.9296 - val_loss: 0.2048 - val_accuracy: 0.9105\n","4 validation loss: 0.20028147101402283\n","9164/9164 [==============================] - 71s 8ms/step\n","MODEL: 5\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 28ms/step - loss: 0.2732 - accuracy: 0.8728 - val_loss: 0.2401 - val_accuracy: 0.8886\n","Epoch 2/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2394 - accuracy: 0.8911 - val_loss: 0.2280 - val_accuracy: 0.8951\n","Epoch 3/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2263 - accuracy: 0.8984 - val_loss: 0.2221 - val_accuracy: 0.8994\n","Epoch 4/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2177 - accuracy: 0.9028 - val_loss: 0.2146 - val_accuracy: 0.9029\n","Epoch 5/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2099 - accuracy: 0.9070 - val_loss: 0.2124 - val_accuracy: 0.9048\n","Epoch 6/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2036 - accuracy: 0.9105 - val_loss: 0.2075 - val_accuracy: 0.9068\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1984 - accuracy: 0.9134 - val_loss: 0.2068 - val_accuracy: 0.9068\n","Epoch 8/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1935 - accuracy: 0.9157 - val_loss: 0.2046 - val_accuracy: 0.9080\n","Epoch 9/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1886 - accuracy: 0.9175 - val_loss: 0.2046 - val_accuracy: 0.9076\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1845 - accuracy: 0.9199 - val_loss: 0.2047 - val_accuracy: 0.9063\n","Epoch 11/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1803 - accuracy: 0.9219 - val_loss: 0.2040 - val_accuracy: 0.9080\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1773 - accuracy: 0.9236 - val_loss: 0.2043 - val_accuracy: 0.9089\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1737 - accuracy: 0.9251 - val_loss: 0.2042 - val_accuracy: 0.9090\n","Epoch 14/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1703 - accuracy: 0.9269 - val_loss: 0.2076 - val_accuracy: 0.9061\n","Epoch 15/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1673 - accuracy: 0.9279 - val_loss: 0.2082 - val_accuracy: 0.9081\n","Epoch 16/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1640 - accuracy: 0.9295 - val_loss: 0.2061 - val_accuracy: 0.9080\n","5 validation loss: 0.2039536088705063\n","9164/9164 [==============================] - 72s 8ms/step\n","MODEL: 6\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 29ms/step - loss: 0.2730 - accuracy: 0.8727 - val_loss: 0.2386 - val_accuracy: 0.8936\n","Epoch 2/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2381 - accuracy: 0.8914 - val_loss: 0.2217 - val_accuracy: 0.9009\n","Epoch 3/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2262 - accuracy: 0.8988 - val_loss: 0.2142 - val_accuracy: 0.9037\n","Epoch 4/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2178 - accuracy: 0.9027 - val_loss: 0.2117 - val_accuracy: 0.9046\n","Epoch 5/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2101 - accuracy: 0.9070 - val_loss: 0.2100 - val_accuracy: 0.9065\n","Epoch 6/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2042 - accuracy: 0.9100 - val_loss: 0.2067 - val_accuracy: 0.9089\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1985 - accuracy: 0.9129 - val_loss: 0.2081 - val_accuracy: 0.9081\n","Epoch 8/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1936 - accuracy: 0.9149 - val_loss: 0.2050 - val_accuracy: 0.9091\n","Epoch 9/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1891 - accuracy: 0.9173 - val_loss: 0.2052 - val_accuracy: 0.9091\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1850 - accuracy: 0.9193 - val_loss: 0.2050 - val_accuracy: 0.9097\n","Epoch 11/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1816 - accuracy: 0.9215 - val_loss: 0.2049 - val_accuracy: 0.9097\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1781 - accuracy: 0.9230 - val_loss: 0.2052 - val_accuracy: 0.9098\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1745 - accuracy: 0.9249 - val_loss: 0.2052 - val_accuracy: 0.9102\n","Epoch 14/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1712 - accuracy: 0.9262 - val_loss: 0.2045 - val_accuracy: 0.9103\n","Epoch 15/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1688 - accuracy: 0.9275 - val_loss: 0.2050 - val_accuracy: 0.9115\n","Epoch 16/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1653 - accuracy: 0.9285 - val_loss: 0.2060 - val_accuracy: 0.9103\n","Epoch 17/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1631 - accuracy: 0.9301 - val_loss: 0.2083 - val_accuracy: 0.9107\n","Epoch 18/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1605 - accuracy: 0.9312 - val_loss: 0.2090 - val_accuracy: 0.9088\n","Epoch 19/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1572 - accuracy: 0.9330 - val_loss: 0.2100 - val_accuracy: 0.9105\n","6 validation loss: 0.20451121032238007\n","9164/9164 [==============================] - 72s 8ms/step\n","MODEL: 7\n","Epoch 1/25\n","1422/1422 [==============================] - 46s 29ms/step - loss: 0.2739 - accuracy: 0.8721 - val_loss: 0.2365 - val_accuracy: 0.8929\n","Epoch 2/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2398 - accuracy: 0.8910 - val_loss: 0.2288 - val_accuracy: 0.8946\n","Epoch 3/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2264 - accuracy: 0.8985 - val_loss: 0.2151 - val_accuracy: 0.9039\n","Epoch 4/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2177 - accuracy: 0.9027 - val_loss: 0.2104 - val_accuracy: 0.9064\n","Epoch 5/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2103 - accuracy: 0.9070 - val_loss: 0.2101 - val_accuracy: 0.9060\n","Epoch 6/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.2042 - accuracy: 0.9101 - val_loss: 0.2103 - val_accuracy: 0.9058\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1987 - accuracy: 0.9130 - val_loss: 0.2052 - val_accuracy: 0.9087\n","Epoch 8/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1938 - accuracy: 0.9151 - val_loss: 0.2067 - val_accuracy: 0.9078\n","Epoch 9/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1899 - accuracy: 0.9173 - val_loss: 0.2016 - val_accuracy: 0.9112\n","Epoch 10/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1855 - accuracy: 0.9187 - val_loss: 0.2030 - val_accuracy: 0.9105\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1817 - accuracy: 0.9209 - val_loss: 0.2032 - val_accuracy: 0.9118\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 27ms/step - loss: 0.1780 - accuracy: 0.9231 - val_loss: 0.2024 - val_accuracy: 0.9109\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1756 - accuracy: 0.9243 - val_loss: 0.2044 - val_accuracy: 0.9099\n","Epoch 14/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1714 - accuracy: 0.9259 - val_loss: 0.2057 - val_accuracy: 0.9094\n","7 validation loss: 0.20156125724315643\n","9164/9164 [==============================] - 73s 8ms/step\n","MODEL: 8\n","Epoch 1/25\n","1422/1422 [==============================] - 47s 29ms/step - loss: 0.2735 - accuracy: 0.8729 - val_loss: 0.2496 - val_accuracy: 0.8840\n","Epoch 2/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2395 - accuracy: 0.8909 - val_loss: 0.2292 - val_accuracy: 0.8959\n","Epoch 3/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2269 - accuracy: 0.8976 - val_loss: 0.2204 - val_accuracy: 0.9014\n","Epoch 4/25\n","1422/1422 [==============================] - 41s 28ms/step - loss: 0.2177 - accuracy: 0.9026 - val_loss: 0.2167 - val_accuracy: 0.9033\n","Epoch 5/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2104 - accuracy: 0.9065 - val_loss: 0.2132 - val_accuracy: 0.9044\n","Epoch 6/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2044 - accuracy: 0.9099 - val_loss: 0.2120 - val_accuracy: 0.9059\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1988 - accuracy: 0.9125 - val_loss: 0.2094 - val_accuracy: 0.9065\n","Epoch 8/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1945 - accuracy: 0.9147 - val_loss: 0.2120 - val_accuracy: 0.9048\n","Epoch 9/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1898 - accuracy: 0.9165 - val_loss: 0.2093 - val_accuracy: 0.9070\n","Epoch 10/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.1849 - accuracy: 0.9192 - val_loss: 0.2082 - val_accuracy: 0.9073\n","Epoch 11/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1821 - accuracy: 0.9211 - val_loss: 0.2132 - val_accuracy: 0.9085\n","Epoch 12/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1781 - accuracy: 0.9225 - val_loss: 0.2110 - val_accuracy: 0.9081\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1748 - accuracy: 0.9248 - val_loss: 0.2146 - val_accuracy: 0.9077\n","Epoch 14/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1717 - accuracy: 0.9262 - val_loss: 0.2129 - val_accuracy: 0.9084\n","Epoch 15/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1681 - accuracy: 0.9277 - val_loss: 0.2153 - val_accuracy: 0.9078\n","8 validation loss: 0.20820631086826324\n","9164/9164 [==============================] - 72s 8ms/step\n","MODEL: 9\n","Epoch 1/25\n","1422/1422 [==============================] - 47s 29ms/step - loss: 0.2737 - accuracy: 0.8725 - val_loss: 0.2408 - val_accuracy: 0.8900\n","Epoch 2/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2391 - accuracy: 0.8913 - val_loss: 0.2298 - val_accuracy: 0.8968\n","Epoch 3/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2260 - accuracy: 0.8987 - val_loss: 0.2214 - val_accuracy: 0.9010\n","Epoch 4/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2169 - accuracy: 0.9031 - val_loss: 0.2173 - val_accuracy: 0.9026\n","Epoch 5/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.2098 - accuracy: 0.9071 - val_loss: 0.2156 - val_accuracy: 0.9029\n","Epoch 6/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.2041 - accuracy: 0.9098 - val_loss: 0.2162 - val_accuracy: 0.9037\n","Epoch 7/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1992 - accuracy: 0.9118 - val_loss: 0.2104 - val_accuracy: 0.9063\n","Epoch 8/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.1937 - accuracy: 0.9149 - val_loss: 0.2102 - val_accuracy: 0.9060\n","Epoch 9/25\n","1422/1422 [==============================] - 41s 29ms/step - loss: 0.1896 - accuracy: 0.9171 - val_loss: 0.2089 - val_accuracy: 0.9074\n","Epoch 10/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1848 - accuracy: 0.9191 - val_loss: 0.2089 - val_accuracy: 0.9073\n","Epoch 11/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1821 - accuracy: 0.9211 - val_loss: 0.2083 - val_accuracy: 0.9076\n","Epoch 12/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1779 - accuracy: 0.9226 - val_loss: 0.2107 - val_accuracy: 0.9069\n","Epoch 13/25\n","1422/1422 [==============================] - 39s 28ms/step - loss: 0.1739 - accuracy: 0.9248 - val_loss: 0.2145 - val_accuracy: 0.9062\n","Epoch 14/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1716 - accuracy: 0.9259 - val_loss: 0.2125 - val_accuracy: 0.9058\n","Epoch 15/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1675 - accuracy: 0.9279 - val_loss: 0.2108 - val_accuracy: 0.9073\n","Epoch 16/25\n","1422/1422 [==============================] - 40s 28ms/step - loss: 0.1653 - accuracy: 0.9284 - val_loss: 0.2122 - val_accuracy: 0.9068\n","9 validation loss: 0.20832520723342896\n","9164/9164 [==============================] - 73s 8ms/step\n"]}]}]}